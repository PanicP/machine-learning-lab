{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 1\n",
    "Assume that a CNN processes data samples of size (32,32,3). Furthermore\n",
    "assume the following structure for the first 6 layers:\n",
    " Conv2D with filter size 3x3, strides 1x1 and 32 filters\n",
    " ReLU\n",
    " MaxPooling2D with kernel size 2x2\n",
    " Conv2D with filter size 4x4, strides 1x1 and 64 filters\n",
    " ReLU\n",
    " MaxPooling2D with kernel size 2x2\n",
    "Please give the dimensions of the first 6 layers as tuples of (H, W, C)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conv2D layer: (30, 30, 32) (assuming \"valid\" padding is used)\n",
    "    ReLU: (30, 30, 32)\n",
    "    MaxPooling2D layer: (15, 15, 32)\n",
    "    Conv2D layer: (12, 12, 64) (assuming \"valid\" padding is used)\n",
    "    ReLU: (12, 12, 64)\n",
    "    MaxPooling2D layer: (6, 6, 64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 2\n",
    "Please give a list of keras layer types and their parameters that would typically\n",
    "be used to perform classification on 28x28x3 image data! There should be at\n",
    "least one convolutional layer and at least two dense (affine) layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 3))\n",
    "    # 32: number of filters\n",
    "    # (3, 3): kernel size\n",
    "    # activation: ReLU activation function\n",
    "    # input_shape: shape of input data (28, 28, 3)\n",
    "keras.layers.MaxPooling2D((2,2))\n",
    "    # (2, 2): pool size\n",
    "keras.layers.Flatten()\n",
    "    # flattens the output from previous layer into a 1D tensor\n",
    "keras.layers.Dense(128, activation='relu')\n",
    "    # 128: number of neurons\n",
    "    # activation: ReLU activation function\n",
    "keras.layers.Dense(10, activation='softmax')\n",
    "    # 10: number of neurons (corresponding to the number of classes)\n",
    "    # activation: softmax activation function to produce a probability distribution over the classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 3\n",
    "Please mark the following statements with true or false, no justification required!\n",
    " All filters in a Conv2D-layer must be identical\n",
    " The number of filters in a conv2D-layer can be chosen arbitrarily\n",
    " The width and height of a conv2D-layer output can be chosen arbitrarily\n",
    " A max-pooling layer must have a kernel size of 2x2\n",
    " A Conv2D-layer must be followed by ReLU\n",
    " A CNN classifier must contain at least one affine layer\n",
    " A CNN classifier can contain an arbitrary number of Conv2D-layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - All filters in a Conv2D-layer must be identical: \n",
    "   False. \n",
    "   Filters in a Conv2D layer can be different and are learned during the training process. \n",
    "   The purpose of filters is to extract different features from the input data.\n",
    "\n",
    "   - The number of filters in a Conv2D-layer can be chosen arbitrarily: \n",
    "   True. \n",
    "   The number of filters in a Conv2D layer can be set to any value, and it depends on the specific problem and architecture being used. \n",
    "   A larger number of filters increases the capacity of the network to learn complex features, but also increases the computational cost.\n",
    "\n",
    "   - The width and height of a Conv2D-layer output can be chosen arbitrarily: \n",
    "   False. \n",
    "   The size of the output from a Conv2D layer depends on the parameters used, such as padding, strides, and kernel size. \n",
    "   If \"valid\" padding is used, the output size will be smaller than the input size. If \"same\" padding is used, \n",
    "   the output size will be the same as the input size. The stride determines how the filter moves across the input, and can also affect the size of the output.\n",
    "\n",
    "   - A max-pooling layer must have a kernel size of 2x2: \n",
    "   False. \n",
    "   The kernel size of a max-pooling layer can be any size, \n",
    "   but 2x2 is a common choice because it has been found to work well in practice and reduces the spatial dimensions of the data efficiently.\n",
    "\n",
    "   - A Conv2D-layer must be followed by ReLU: \n",
    "   False. \n",
    "   There is no requirement that a Conv2D layer must be followed by ReLU. \n",
    "   Different activation functions can be used depending on the specific architecture being used. \n",
    "   ReLU is a commonly used activation function because it is simple and has been found to work well in practice.\n",
    "\n",
    "   - A CNN classifier must contain at least one affine layer: \n",
    "   True. \n",
    "   An affine layer, also known as a dense layer, is typically used for the final classification in a CNN classifier. \n",
    "   The output from the Conv2D and max-pooling layers is typically flattened into a 1D tensor, and then passed through one or more dense layers for the final classification.\n",
    "\n",
    "   - A CNN classifier can contain an arbitrary number of Conv2D-layers: \n",
    "   True. \n",
    "   There is no limit to the number of Conv2D layers that can be used in a CNN classifier. \n",
    "   The number of Conv2D layers used depends on the specific problem and architecture being used. \n",
    "   A deep network with many Conv2D layers can learn complex features, but also increases the computational cost and can lead to overfitting.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced numpy\n",
    "For-loops are forbidden here!!\n",
    "\n",
    "a) Give a code snippet that create two random 1D arrays of length 20, with\n",
    "integer entries between 0 and 3 (included). Then, the code should compute the\n",
    "confusion matrix from these two vectors.\n",
    "\n",
    "b) Give a code snippet that generates two 1D arrays with values from 0 to 19\n",
    "(included) in ascending order. Then, the code should shuffle both arrays such\n",
    "that same positions contain same values after shuffling (like you would shuffle\n",
    "train data and labels).\n",
    "\n",
    "c) Give a code snippet that creates a 1D array with random values from 0 to\n",
    "9 (included). Then, interpret this array as scalar targets and create a one-hot\n",
    "representation for them, assuming 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 1 3 3 2 2 0 3 1 3 0 2 3 0 2 3 2 3] [0 3 3 1 2 1 2 3 2 2 2 1 1 0 0 2 3 1 1 2]\n",
      "[[0 1 2 0]\n",
      " [0 1 1 0]\n",
      " [2 1 1 3]\n",
      " [1 3 3 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create two random 1D arrays of length 20 with integer entries between 0 and 3\n",
    "y_true = np.random.randint(0, 4, 20)\n",
    "y_pred = np.random.randint(0, 4, 20)\n",
    "print(y_true, y_pred)\n",
    "# Compute the confusion matrix using np.add.at and without using a for-loop\n",
    "confusion_matrix = np.zeros((4, 4), dtype=int)\n",
    "np.add.at(confusion_matrix, (y_true, y_pred), 1)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  5 18  6 11 16  1 13  2 12 19  7 10 14 17  4  0  8  3 15]\n",
      "[ 9  5 18  6 11 16  1 13  2 12 19  7 10 14 17  4  0  8  3 15]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate two 1D arrays with values from 0 to 19 in ascending order\n",
    "a = np.arange(20)\n",
    "b = np.arange(20)\n",
    "\n",
    "# Generate a random permutation of indices\n",
    "permutation = np.random.permutation(20)\n",
    "\n",
    "# Shuffle both arrays such that same positions contain same values after shuffling\n",
    "a = a[permutation]\n",
    "b = b[permutation]\n",
    "\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 5 3 9 3 0 6 7 6 4 7 5 0 0 1 8 1 6 7 5]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 1D array with random values from 0 to 9 (included)\n",
    "targets = np.random.randint(0, 10, size=(20,))\n",
    "\n",
    "# Create a one-hot representation for the targets, assuming 10 classes\n",
    "one_hot_targets = np.zeros((20, 10))\n",
    "one_hot_targets[np.arange(20), targets] = 1\n",
    "\n",
    "print(targets)\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities\n",
    "\n",
    "Consider these experimental results for X and Y:\n",
    "Exp 1 (X): 1 1 1 1 2 2 2 2 1 1 1 1\n",
    "Exp 2 (Y): 2 1 1 2 1 2 3 1 3 1 1 3 \n",
    "Compute:\n",
    "a) #(Y = 1), #(Y = 2), #(Y = 3)\n",
    "b) #(X = 1, Y = 1), #(X = 1, Y = 2), #(X = 1, Y = 3)\n",
    "c) p(X = 1, Y = 1), p(X = 1, Y = 2), p(X = 1, Y = 3)\n",
    "d) p(X = 1|Y = 1), p(X = 1|Y = 2), p(X = 1|Y = 3)\n",
    "e) p(Y = 1|X = 1)\n",
    "f ) p(X = 1|Y ̸ = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) 6        3       3\n",
    "b) 4        2       2\n",
    "c) 4/12     2/12    2/12\n",
    "d) 4/6      2/3     2/3\n",
    "e) 4/8\n",
    "f ) 4/6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix\n",
    "\n",
    "Evaluation of a classifier yields the following CM:\n",
    "\n",
    "10 60 10\n",
    "0 80 0\n",
    "0 20 60\n",
    "\n",
    "Compute:\n",
    "a) Nr of test samples\n",
    "b) p(ˆy = 1|ˆt = 2)\n",
    "c) p(ˆt = 1), p(ˆt = 2), p(ˆy = 2)\n",
    "d) Probability of an incorrect classification when restricting ourselves to classifer outputs of 2.\n",
    "e) Probability of an incorrect classification\n",
    " y = แนวนอน t = แนวตั้ง start at 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) sum all\n",
    "10 + 60 + 10 + 0 + 80 + 0 + 0 + 20 + 60 => 240\n",
    "b) \n",
    "0 / 0 + 80 + 0 = 0\n",
    "c) \n",
    "10 + 60 + 10 / 240 = 80/240, \n",
    "0 + 80 + 0 / 240 = 80/240, \n",
    "60 + 80 + 20 / 240 = 160/240\n",
    "d) p(y^ != t^ | y^ = 2) \n",
    "60 + 20 / 160 = 80/160\n",
    "e) (y^ != t^)\n",
    "60 + 10 + 0 + 0 + 0 + 20 / 240 = 90/240\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classification 1\n",
    "\n",
    "A binary classifier that always chooses the negative class is evaluated on a test\n",
    "set in which the proportion between positive and negative samples as 1:9. Com-\n",
    "pute:\n",
    "a) tpr, fnr\n",
    "b) fpr, tnr\n",
    "c) classification error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fca71db0846ed8da79651cc37ae136c353db3e2c5a5b78df660c892d8bb501f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
